import os
os.environ["PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION"] = "python"

# ç¡®ä¿åœ¨Windowsä¸Šä½¿ç”¨æ­£ç¡®çš„äº‹ä»¶å¾ªç¯ç­–ç•¥
if os.name == 'nt':  # Windowsç³»ç»Ÿ
    import asyncio
    try:
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    except Exception as e:
        print(f"æ— æ³•è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥: {e}")

import streamlit as st
import os
import sys
from pathlib import Path
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
import torch
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))

from model.config.train_config import TrainConfig
from model.core.model_factory import ModelFactory
from model.core.trainer import Trainer
from model.dataloader.dataset import create_dataloaders
from model.utils.dataset_sampler import DatasetSampler

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TrainingVisualizer:
    def __init__(self):
        self.config = TrainConfig()
        self.history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': [],
            'lr': []
        }
        
    def update_plots(self):
        """æ›´æ–°è®­ç»ƒè¿‡ç¨‹å›¾è¡¨"""
        if not self.history['train_loss']:
            return
            
        df = pd.DataFrame(self.history)
        
        # åˆ›å»ºå­å›¾
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('Loss', 'Accuracy'),
            vertical_spacing=0.15
        )
        
        # æ·»åŠ æŸå¤±æ›²çº¿
        fig.add_trace(
            go.Scatter(y=df['train_loss'], name='Train Loss', line=dict(color='blue')),
            row=1, col=1
        )
        fig.add_trace(
            go.Scatter(y=df['val_loss'], name='Val Loss', line=dict(color='red')),
            row=1, col=1
        )
        
        # æ·»åŠ å‡†ç¡®ç‡æ›²çº¿
        fig.add_trace(
            go.Scatter(y=df['train_acc'], name='Train Acc', line=dict(color='blue')),
            row=2, col=1
        )
        fig.add_trace(
            go.Scatter(y=df['val_acc'], name='Val Acc', line=dict(color='red')),
            row=2, col=1
        )
        
        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            height=600,
            showlegend=True,
            title_text='Training Progress'
        )
        
        # æ˜¾ç¤ºå›¾è¡¨
        st.plotly_chart(fig, use_container_width=True)
        
    def train_epoch_callback(self, epoch, train_metrics, val_metrics, lr):
        """æ¯ä¸ªepochç»“æŸåçš„å›è°ƒå‡½æ•°"""
        self.history['train_loss'].append(train_metrics['loss'])
        self.history['train_acc'].append(train_metrics['acc'])
        self.history['val_loss'].append(val_metrics['loss'])
        self.history['val_acc'].append(val_metrics['acc'])
        self.history['lr'].append(lr)
        
        # æ›´æ–°è¿›åº¦æ¡
        progress_bar.progress((epoch + 1) / self.config.EPOCHS)
        
        # æ›´æ–°æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Train Loss", f"{train_metrics['loss']:.4f}")
        with col2:
            st.metric("Train Acc", f"{train_metrics['acc']:.2f}%")
        with col3:
            st.metric("Val Loss", f"{val_metrics['loss']:.4f}")
        with col4:
            st.metric("Val Acc", f"{val_metrics['acc']:.2f}%")
            
        # æ›´æ–°å›¾è¡¨
        self.update_plots()
        
    def prepare_dataset(self, source_dir, sample_size):
        """å‡†å¤‡æ•°æ®é›†"""
        self.config.DATASET_SAMPLE_SIZE = sample_size
        
        # è®¾ç½®ç›®æ ‡è·¯å¾„
        train_dir = os.path.join('data', 'train')
        val_dir = os.path.join('data', 'val')
        
        # åˆ›å»ºé‡‡æ ·å™¨å¹¶å¤„ç†æ•°æ®é›†
        sampler = DatasetSampler(self.config)
        sampler.process_dataset(source_dir, train_dir, val_dir)
        
    def train(self):
        """å¼€å§‹è®­ç»ƒ"""
        try:
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            train_loader, val_loader = create_dataloaders(self.config)
            
            # ç›´æ¥åˆ›å»ºæ¨¡å‹
            model = ModelFactory.create_model(
                model_name=self.config.MODEL_NAME,
                num_classes=self.config.NUM_CLASSES,
                pretrained=self.config.PRETRAINED
            )
            
            # ç›´æ¥åˆ›å»ºä¼˜åŒ–å™¨
            optimizer = ModelFactory.create_optimizer(
                model=model,
                optimizer_name='AdamW',
                lr=self.config.LEARNING_RATE,
                weight_decay=self.config.WEIGHT_DECAY,
                amsgrad=True
            )
            
            # åˆ›å»ºæŸå¤±å‡½æ•°
            criterion = ModelFactory.create_criterion()
            
            # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
            scheduler = ModelFactory.create_scheduler(
                optimizer=optimizer,
                scheduler_name='CosineAnnealingWarmRestarts',
                T_0=10,
                T_mult=2,
                eta_min=1e-6
            )
            
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = Trainer(
                model=model,
                optimizer=optimizer,
                criterion=criterion,
                scheduler=scheduler,
                config=self.config,
                device=self.config.DEVICE
            )
            
            # è®¾ç½®è¿›åº¦æ¡
            progress_bar = st.progress(0)
            
            # å¼€å§‹è®­ç»ƒ
            for epoch in range(self.config.EPOCHS):
                # è®­ç»ƒä¸€ä¸ªepoch
                train_metrics = trainer.train_epoch(train_loader)
                
                # éªŒè¯
                val_metrics = trainer.validate(val_loader)
                
                # è·å–å½“å‰å­¦ä¹ ç‡
                current_lr = optimizer.param_groups[0]['lr']
                
                # æ›´æ–°å›è°ƒ
                self.train_epoch_callback(
                    epoch,
                    train_metrics,
                    val_metrics,
                    current_lr
                )
                
                # æ›´æ–°è¿›åº¦æ¡
                progress_bar.progress((epoch + 1) / self.config.EPOCHS)
                
                # å­¦ä¹ ç‡è°ƒåº¦å™¨æ­¥è¿›
                if scheduler is not None:
                    scheduler.step()
                    
            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            os.makedirs(self.config.CHECKPOINT_DIR, exist_ok=True)
            trainer.save_checkpoint(self.config.BEST_MODEL_PATH)
            st.success(f"è®­ç»ƒå®Œæˆï¼æ¨¡å‹ä¿å­˜åœ¨ {self.config.BEST_MODEL_PATH}")
            
        except Exception as e:
            logger.error(f"Error during training: {e}")
            st.error(f"è®­ç»ƒå‡ºé”™: {e}")
            import traceback
            logger.error(traceback.format_exc())
            st.stop()

def main():
    st.set_page_config(
        page_title="æ¤ç‰©ç—…è™«å®³è¯†åˆ«ç³»ç»Ÿ - è®­ç»ƒé¢æ¿",
        page_icon="ğŸŒ¿",
        layout="wide"
    )
    
    st.title("æ¤ç‰©ç—…è™«å®³è¯†åˆ«ç³»ç»Ÿ - è®­ç»ƒé¢æ¿")
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    visualizer = TrainingVisualizer()
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("è®­ç»ƒé…ç½®")
        
        # æ•°æ®é›†é…ç½®
        st.subheader("æ•°æ®é›†é…ç½®")
        source_dir = st.text_input(
            "æ•°æ®é›†ç›®å½•",
            value="datasets/PlantVillage/color",
            help="åŸå§‹æ•°æ®é›†çš„ç›®å½•è·¯å¾„"
        )
        
        sample_size = st.slider(
            "æ•°æ®é›†é‡‡æ ·æ¯”ä¾‹",
            min_value=0.1,
            max_value=1.0,
            value=0.1,
            step=0.1,
            help="ä½¿ç”¨åŸå§‹æ•°æ®é›†çš„æ¯”ä¾‹"
        )
        
        # è®­ç»ƒé…ç½®
        st.subheader("è®­ç»ƒé…ç½®")
        visualizer.config.EPOCHS = st.number_input(
            "è®­ç»ƒè½®æ•°",
            min_value=1,
            max_value=100,
            value=10
        )
        
        visualizer.config.BATCH_SIZE = st.number_input(
            "æ‰¹æ¬¡å¤§å°",
            min_value=1,
            max_value=128,
            value=32
        )
        
        visualizer.config.LEARNING_RATE = st.number_input(
            "å­¦ä¹ ç‡",
            min_value=0.0001,
            max_value=0.1,
            value=0.001,
            format="%f"
        )
        
        # å¼€å§‹è®­ç»ƒæŒ‰é’®
        if st.button("å¼€å§‹è®­ç»ƒ"):
            try:
                # å‡†å¤‡æ•°æ®é›†
                with st.spinner("å‡†å¤‡æ•°æ®é›†ä¸­..."):
                    visualizer.prepare_dataset(source_dir, sample_size)
                
                # åˆ›å»ºè¿›åº¦æ¡
                global progress_bar
                progress_bar = st.progress(0)
                
                # åˆ›å»ºæŒ‡æ ‡æ˜¾ç¤ºåŒº
                st.subheader("è®­ç»ƒæŒ‡æ ‡")
                metrics_container = st.empty()
                
                # å¼€å§‹è®­ç»ƒ
                start_time = datetime.now()
                visualizer.train()
                end_time = datetime.now()
                
                # æ˜¾ç¤ºè®­ç»ƒå®Œæˆä¿¡æ¯
                training_time = end_time - start_time
                st.success(f"è®­ç»ƒå®Œæˆï¼æ€»ç”¨æ—¶: {training_time}")
                
            except Exception as e:
                st.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                logger.error(f"Error during training: {str(e)}")

if __name__ == "__main__":
    main() 